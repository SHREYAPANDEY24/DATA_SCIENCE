{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdb937f-c947-4f96-85d2-ac95bd42dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "\n",
    "# Answer:\n",
    "# Simple linear regression models the relationship between two variables: one independent variable (X) and one dependent variable (Y).\n",
    "# The model is expressed as Y = b0 + b1*X + ε, where b0 is the intercept, b1 is the slope, and ε is the error term.\n",
    "\n",
    "# Example of Simple Linear Regression:\n",
    "# Predicting a person's weight (Y) based on their height (X).\n",
    "\n",
    "# Multiple linear regression, on the other hand, models the relationship between a dependent variable (Y) and two or more independent variables (X1, X2, ..., Xn).\n",
    "# The model is expressed as Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + ε.\n",
    "\n",
    "# Example of Multiple Linear Regression:\n",
    "# Predicting a person's weight (Y) based on their height (X1), age (X2), and exercise frequency (X3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb19019-3e94-4226-a11a-9edc02acc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "\n",
    "# Answer:\n",
    "# The key assumptions of linear regression are:\n",
    "# 1. Linearity: The relationship between the independent and dependent variables should be linear.\n",
    "# 2. Independence: Observations should be independent of each other.\n",
    "# 3. Homoscedasticity: The residuals (errors) should have constant variance.\n",
    "# 4. Normality: The residuals should be normally distributed.\n",
    "# 5. No Multicollinearity: Independent variables should not be highly correlated with each other.\n",
    "\n",
    "# To check these assumptions:\n",
    "# - Linearity: Use scatter plots of the dependent variable against each independent variable.\n",
    "# - Independence: Check the Durbin-Watson statistic for autocorrelation.\n",
    "# - Homoscedasticity: Plot residuals vs. fitted values and look for patterns.\n",
    "# - Normality: Use a Q-Q plot or a Shapiro-Wilk test to assess the normality of residuals.\n",
    "# - Multicollinearity: Use Variance Inflation Factor (VIF) to detect multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f661ce-8f7e-4af5-9f68-cb5220475a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "\n",
    "# Answer:\n",
    "# In a linear regression model, the slope (b1) represents the change in the dependent variable (Y) for a one-unit change in the independent variable (X).\n",
    "# The intercept (b0) represents the value of Y when X is 0.\n",
    "\n",
    "# Example:\n",
    "# Suppose you have a linear regression model predicting the price of a house (Y) based on its size in square feet (X).\n",
    "# If the slope is 150, it means that for every additional square foot, the price of the house increases by $150.\n",
    "# If the intercept is 50,000, it means that the base price of the house (when size is 0) is $50,000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a07585b-a594-4578-b7cf-4d44a46e8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "# Answer:\n",
    "# Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models.\n",
    "# It iteratively adjusts the model parameters by moving them in the direction of the steepest descent of the cost function, i.e., where the gradient is negative.\n",
    "\n",
    "# The learning rate controls the step size in each iteration. The algorithm stops when it converges, i.e., when further adjustments result in minimal changes to the cost function.\n",
    "\n",
    "# Gradient descent is used in training machine learning models, especially in linear regression, logistic regression, and neural networks, to find the optimal parameters that minimize prediction errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a110dac-08bd-4847-be2b-e14fce7b15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "# Answer:\n",
    "# Multiple linear regression models the relationship between a dependent variable (Y) and multiple independent variables (X1, X2, ..., Xn).\n",
    "# The model is expressed as Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + ε, where each coefficient (bi) represents the impact of the corresponding independent variable on Y.\n",
    "\n",
    "# The key difference from simple linear regression is the inclusion of multiple predictors in the model, allowing for a more complex and accurate representation of the factors influencing the dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772fd9b5-9abb-4141-9bc5-5bddb197d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "\n",
    "# Answer:\n",
    "# Multicollinearity occurs when two or more independent variables in a multiple linear regression model are highly correlated.\n",
    "# This can lead to inflated standard errors and unreliable coefficient estimates, making it difficult to assess the importance of individual predictors.\n",
    "\n",
    "# Detection:\n",
    "# - Variance Inflation Factor (VIF): A VIF value greater than 10 indicates high multicollinearity.\n",
    "# - Correlation matrix: Check for high correlation coefficients (close to 1 or -1) among independent variables.\n",
    "\n",
    "# Addressing multicollinearity:\n",
    "# - Remove or combine highly correlated variables.\n",
    "# - Use regularization techniques like Ridge or Lasso regression to penalize large coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4703ce42-8583-462a-82cb-ff7520e62436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "# Answer:\n",
    "# Polynomial regression is an extension of linear regression where the relationship between the independent and dependent variables is modeled as an nth degree polynomial.\n",
    "# The model is expressed as Y = b0 + b1*X + b2*X^2 + ... + bn*X^n + ε, where n is the degree of the polynomial.\n",
    "\n",
    "# Unlike linear regression, which models a straight-line relationship, polynomial regression can model more complex, non-linear relationships by fitting a curve to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dad29d8-1779-4565-b022-591d6a9d4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "# Answer:\n",
    "# Advantages of Polynomial Regression:\n",
    "# - Can model complex, non-linear relationships that linear regression cannot capture.\n",
    "# - Provides a more flexible fit to the data.\n",
    "\n",
    "# Disadvantages:\n",
    "# - Higher-degree polynomials can lead to overfitting, where the model captures noise rather than the true relationship.\n",
    "# - More complex models are harder to interpret.\n",
    "\n",
    "# Polynomial regression is preferred when the relationship between the independent and dependent variables is non-linear, and a linear model would not provide a good fit.\n",
    "# It is commonly used in scenarios like growth curves, dose-response relationships, and other cases where the data exhibits a curved trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bb38d-7dd4-4b89-ad51-18a2765028f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
